{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73b73610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Credntials From File...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from googleHelpers import *\n",
    "\n",
    "youtube = Youtube()\n",
    "\n",
    "# Getting my top 20 categories by vid count and mins watched from 2018-2021\n",
    "videoHistory = youtube.videoHistory\n",
    "\n",
    "videoHistory = videoHistory.drop(\n",
    "    [\n",
    "        'Unnamed: 0', 'description', 'viewCount',\n",
    "    ],\n",
    "    axis = 1\n",
    ")\n",
    "\n",
    "# Adding year for filtering \n",
    "videoHistory[\"searchYear\"] = pd.DatetimeIndex(videoHistory.timestamp).year\n",
    "\n",
    "# Adding a column for duration in units of minutes\n",
    "duration = []\n",
    "for index, row in videoHistory.iterrows():\n",
    "    video_duration = 0\n",
    "    hours = re.search('\\d*H', row['duration'])\n",
    "    minutes = re.search('\\d*M', row['duration'])\n",
    "    seconds = re.search('\\d*S', row['duration'])\n",
    "    if hours:\n",
    "        video_duration += (int(hours.group()[ :-1]) * 60)\n",
    "    if minutes:\n",
    "        video_duration += int(minutes.group()[ :-1])\n",
    "    if seconds:\n",
    "        video_duration += (int(seconds.group()[ :-1]) / 60)\n",
    "    duration.append(video_duration)\n",
    "    \n",
    "videoHistory['duration'] = duration\n",
    "\n",
    "categoryPopularity = videoHistory.groupby(\n",
    "    'categoryTitle'\n",
    "    ).count(\n",
    "    ).sort_values(\n",
    "    'id', \n",
    "    ascending=False\n",
    "    ).rename(columns={\n",
    "    'id':'n'\n",
    "    })['n'].reset_index()\n",
    "\n",
    "channelCategories = videoHistory[['categoryTitle', 'channelTitle']].drop_duplicates().merge(\n",
    "    categoryPopularity,\n",
    ").groupby('channelTitle').max().reset_index()\n",
    "\n",
    "channelCategories = channelCategories[\n",
    "    channelCategories.groupby('channelTitle').n.transform(lambda x: x == x.max())\n",
    "    ]\n",
    "\n",
    "videoHistory = videoHistory.drop(\n",
    "    'categoryTitle', axis=1\n",
    ").merge(\n",
    "    channelCategories\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e33d781",
   "metadata": {},
   "outputs": [],
   "source": [
    "categoryData = videoHistory.groupby(['categoryTitle', 'searchYear']).aggregate(\n",
    "    np.sum\n",
    ").rename(\n",
    "    columns = {\n",
    "        \"duration\": \"minPlayed\"\n",
    "    }\n",
    ").drop(\n",
    "    ['categoryId'], \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "categoryData = categoryData.assign(\n",
    "    hrsPlayed=categoryData['minPlayed'] / 60\n",
    ").drop(\n",
    "    'minPlayed',\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "timesPlayed = videoHistory.groupby(\n",
    "    ['categoryTitle', 'searchYear']\n",
    ").count().rename(columns={\n",
    "    'id':'videosWatched'\n",
    "})['videosWatched']\n",
    "\n",
    "categoryData = categoryData.merge(\n",
    "    timesPlayed,\n",
    "    'inner',\n",
    "    left_on = ['categoryTitle', 'searchYear'],\n",
    "    right_index = True\n",
    ")\n",
    "\n",
    "categoryData.sort_values(\n",
    "    ['searchYear', 'hrsPlayed', 'videosWatched'],\n",
    "    ascending=False\n",
    ").to_csv('tableauData/youtubeCategoryData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "072af9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting my top 20 channels by vid count and mins watched from 2018-2021\n",
    "channelData =  videoHistory.groupby(\n",
    "    ['channelTitle', 'searchYear']\n",
    ").aggregate(\n",
    "    np.sum\n",
    ").rename(\n",
    "    columns = {\n",
    "        \"duration\": \"minPlayed\"\n",
    "    }\n",
    ").drop(\n",
    "    ['categoryId', 'n'], \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "channelData = channelData.assign(\n",
    "    hrsPlayed=channelData['minPlayed'] / 60\n",
    ").drop(\n",
    "    'minPlayed',\n",
    "    axis=1\n",
    ").reset_index()\n",
    "\n",
    "timesPlayed = videoHistory.groupby(\n",
    "    ['channelTitle', 'searchYear']\n",
    ").count().rename(columns={\n",
    "    'id':'videosWatched'\n",
    "})['videosWatched']\n",
    "\n",
    "channelData = channelData.merge(\n",
    "    timesPlayed,\n",
    "    'inner',\n",
    "    left_on = ['channelTitle', 'searchYear'],\n",
    "    right_index = True\n",
    ")\n",
    "    \n",
    "channelData.sort_values(\n",
    "    ['searchYear', 'hrsPlayed', 'videosWatched'],\n",
    "    ascending=False\n",
    ").groupby(\n",
    "    ['searchYear']\n",
    ").head(\n",
    "    50\n",
    ").merge(\n",
    "    videoHistory[['channelTitle', 'categoryTitle']].drop_duplicates()\n",
    ").to_csv('tableauData/youtubeChannelData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3feb4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the Top 20 searches per year from 2018-2021\n",
    "searchHistory = youtube.searchHistory.copy()\n",
    "searchHistory[\"searchYear\"] = pd.DatetimeIndex(searchHistory.timestamp).year\n",
    "searchHistory['timestamp'] = pd.to_datetime(searchHistory['timestamp'])\n",
    "\n",
    "\n",
    "searchHistory.assign(\n",
    "    count = 1\n",
    ").groupby(\n",
    "    ['query', 'searchYear']\n",
    ").aggregate(\n",
    "    np.sum\n",
    ").drop(\n",
    "    'Unnamed: 0',\n",
    "    axis = 1\n",
    ").sort_values(\n",
    "    'count',\n",
    "    ascending=False\n",
    ").groupby(\n",
    "    ['searchYear']\n",
    ").head(\n",
    "    20\n",
    ").to_csv('tableauData/youtubeRawSearchCounts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5c57b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of words analysis on youtube searches from December 2020 - Febuary 2021\n",
    "text = searchHistory.loc[\n",
    "    (searchHistory['timestamp'] > '2021-01-01') &\n",
    "    (searchHistory['timestamp'] < '2021-04-01'),\n",
    "    ['query', 'timestamp']\n",
    "]\n",
    "\n",
    "# Tokenize text words\n",
    "text_corpus = ' '.join(text['query'])\n",
    "tokens = nltk.word_tokenize(text_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d91a743f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing stop words and lemmanting words\n",
    "word_lem=nltk.stem.WordNetLemmatizer()\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "lem_tokens = []\n",
    "for word in tokens:\n",
    "    if word in stopwords:\n",
    "        continue\n",
    "    lem_tokens.append(word_lem.lemmatize(word.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4b2ba18",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist = nltk.probability.FreqDist()\n",
    "# Creating a data structure to store word freq\n",
    "for word in lem_tokens:\n",
    "    fdist[word.lower()]+=1\n",
    "# Saving the data into a df and writing to a csv\n",
    "q1YoutubeSearches = pd.DataFrame().from_dict(dict(fdist), orient = 'index')\n",
    "q1YoutubeSearches.to_csv('tableauData/youtubeSearches2021q1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a952ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I bought 12 books in 2020\n",
      "I bought 22 books in 2021\n"
     ]
    }
   ],
   "source": [
    "# Pull amazon book purchases from 2021\n",
    "amzn = {\n",
    "    \"exp20\":pd.read_csv('data/amazon2020.csv'),\n",
    "    \"exp21\":pd.read_csv('data/amazon2021.csv')\n",
    "}\n",
    "\n",
    "# Filtering for book purchases\n",
    "books20 = amzn['exp20'][amzn['exp20']['Category'] == \"ABIS_BOOK\"].copy()\n",
    "books21 = amzn['exp21'][amzn['exp21']['Category'] == \"ABIS_BOOK\"].copy()\n",
    "\n",
    "# Books bought in 20 & 21\n",
    "print(\"I bought\", books20.count().max(), 'books in 2020')\n",
    "print('I bought', books21.count().max(), 'books in 2021')\n",
    "\n",
    "# Creating csv files for amazon data\n",
    "books20.append(books21).to_csv('tableauData/amazonBookPurchases.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
